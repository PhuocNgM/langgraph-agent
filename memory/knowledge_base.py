# memory/knowledge_base.py
import os
from typing import List
from dotenv import load_dotenv 

# --- C√ÅC IMPORT QUAN TR·ªåNG (ƒê·ª´ng x√≥a) ---
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter 
from .vector_store import VectorStore
# ----------------------------------------

try:
    load_dotenv()
except Exception:
    pass

class KnowledgeBase:
    def __init__(self, path="./memory/knowledge_base_store"):
        # vector store definition     
        self.store = VectorStore(path)
        print(f"INFO: Initialized KnowledgeBase at: {path}")

    def ingest_from_directory(self, directory_path: str = "./data"):
        """
        adding one by one files.
        """
        # 1. Ki·ªÉm tra th∆∞ m·ª•c t·ªìn t·∫°i
        if not os.path.exists(directory_path):
            print(f"ERROR: Directory '{directory_path}' does not exist.")
            return
        
        print(f"--- Starting Ingestion from: {directory_path} ---")

        # 2. Qu√©t to√†n b·ªô file trong th∆∞ m·ª•c
        pdf_files = []
        txt_files = []
        
        for root, dirs, files in os.walk(directory_path):
            for file in files:
                if file.lower().endswith(".pdf"):
                    pdf_files.append(os.path.join(root, file))
                elif file.lower().endswith(".txt"):
                    txt_files.append(os.path.join(root, file))

        documents = []

        # 3. Load t·ª´ng file PDF (An to√†n)
        print(f"Found {len(pdf_files)} PDF files. Processing one by one...")
        for pdf_path in pdf_files:
            try:
                # D√πng PyPDFLoader cho t·ª´ng file
                loader = PyPDFLoader(pdf_path) 
                docs = loader.load()
                documents.extend(docs)
                print(f"  ‚úÖ Loaded: {os.path.basename(pdf_path)}")
            except Exception as e:
                # N·∫øu file l·ªói, in ra warning v√† b·ªè qua, kh√¥ng crash ch∆∞∆°ng tr√¨nh
                print(f"  ‚ùå SKIPPING corrupted file: {os.path.basename(pdf_path)} - Error: {e}")

        # 4. Load t·ª´ng file TXT (An to√†n)
        print(f"Found {len(txt_files)} TXT files...")
        for txt_path in txt_files:
            try:
                loader = TextLoader(txt_path)
                docs = loader.load()
                documents.extend(docs)
                print(f"  ‚úÖ Loaded: {os.path.basename(txt_path)}")
            except Exception as e:
                print(f"  ‚ùå SKIPPING file: {os.path.basename(txt_path)}")

        if not documents:
            print("WARNING: No valid documents loaded. Stopping.")
            return

        # 5. Chia nh·ªè vƒÉn b·∫£n (Splitting)
        print(f"Splitting {len(documents)} documents...")
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        texts = text_splitter.split_documents(documents)
        print(f"  > Generated {len(texts)} raw text chunks.")

        # 6. L·ªçc v√† l√†m s·∫°ch d·ªØ li·ªáu
        string_texts = []
        for doc in texts:
            content = doc.page_content.strip()
            # Ch·ªâ l·∫•y c√°c ƒëo·∫°n c√≥ n·ªôi dung d√†i h∆°n 5 k√Ω t·ª±
            if len(content) > 5: 
                string_texts.append(content)

        if not string_texts:
            print("WARNING: No valid chunks generated.")
            return

        # 7. N·∫°p v√†o VectorStore theo l√¥ (Batching)
        total_chunks = len(string_texts)
        BATCH_SIZE = 2000 
        
        print(f"üíæ Ingesting {total_chunks} chunks into VectorStore (Batch Size: {BATCH_SIZE})...")
        
        for i in range(0, total_chunks, BATCH_SIZE):
            batch = string_texts[i : i + BATCH_SIZE]
            batch_num = (i // BATCH_SIZE) + 1
            
            try:
                print(f"  > Processing Batch {batch_num} ({len(batch)} chunks)...")
                self.store.add(batch)
            except Exception as e:
                print(f"  ‚ùå Error adding Batch {batch_num}: {e}")
                
        print("‚úÖ Ingestion process completed successfully.")

    def query(self, question: str) -> List[str]:
        """
        Truy v·∫•n d·ªØ li·ªáu.
        """
        try:
            results = self.store.search(question, top_k=5)
            # Tr·∫£ v·ªÅ list text
            return [text for text in results] 
        except Exception as e:
            print(f"Query Error: {e}")
            return []